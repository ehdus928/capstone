{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68dd64c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "conn_string = \"\"\n",
    "conn = psycopg2.connect(conn_string)\n",
    "cur=conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT * FROM capstone.cap_data;\")\n",
    "result = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba2b4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>intime</th>\n",
       "      <th>outtime</th>\n",
       "      <th>information</th>\n",
       "      <th>readmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31792</td>\n",
       "      <td>25996</td>\n",
       "      <td>135999</td>\n",
       "      <td>2200-04-14 19:12:00</td>\n",
       "      <td>2200-04-16 18:11:00</td>\n",
       "      <td>[**2200-4-16**] 12:21 PM\\n CT HEAD W/O CONTRAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55392</td>\n",
       "      <td>88857</td>\n",
       "      <td>136000</td>\n",
       "      <td>2109-12-05 21:48:10</td>\n",
       "      <td>2109-12-06 16:16:49</td>\n",
       "      <td>Chief Complaint: ETOH withdrawal\\n   I saw and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5401</td>\n",
       "      <td>4461</td>\n",
       "      <td>136001</td>\n",
       "      <td>2127-02-02 20:52:14</td>\n",
       "      <td>2127-03-02 15:16:49</td>\n",
       "      <td>[**2127-2-4**] 5:38 AM\\n CHEST (PORTABLE AP)  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13893</td>\n",
       "      <td>11342</td>\n",
       "      <td>136006</td>\n",
       "      <td>2176-06-04 19:13:08</td>\n",
       "      <td>2176-06-06 22:21:21</td>\n",
       "      <td>NURSING MICU NOTE 7P-7A\\n\\n46Y/O FEMALE PRESEN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7825</td>\n",
       "      <td>6428</td>\n",
       "      <td>136010</td>\n",
       "      <td>2116-05-27 10:47:22</td>\n",
       "      <td>2116-05-29 15:35:55</td>\n",
       "      <td>[**2116-5-29**] 1:42 PM\\n [**Last Name (un) 26...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  subject_id  hadm_id              intime             outtime  \\\n",
       "0   31792       25996   135999 2200-04-14 19:12:00 2200-04-16 18:11:00   \n",
       "1   55392       88857   136000 2109-12-05 21:48:10 2109-12-06 16:16:49   \n",
       "2    5401        4461   136001 2127-02-02 20:52:14 2127-03-02 15:16:49   \n",
       "3   13893       11342   136006 2176-06-04 19:13:08 2176-06-06 22:21:21   \n",
       "4    7825        6428   136010 2116-05-27 10:47:22 2116-05-29 15:35:55   \n",
       "\n",
       "                                         information  readmission  \n",
       "0  [**2200-4-16**] 12:21 PM\\n CT HEAD W/O CONTRAS...            0  \n",
       "1  Chief Complaint: ETOH withdrawal\\n   I saw and...            0  \n",
       "2  [**2127-2-4**] 5:38 AM\\n CHEST (PORTABLE AP)  ...            0  \n",
       "3  NURSING MICU NOTE 7P-7A\\n\\n46Y/O FEMALE PRESEN...            0  \n",
       "4  [**2116-5-29**] 1:42 PM\\n [**Last Name (un) 26...            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"row_id\",\"subject_id\",\"hadm_id\",\"intime\",\"outtime\",\"information\",'readmission']\n",
    "df = pd.DataFrame(result,columns = columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a3db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(x):\n",
    "    y=re.sub('\\\\[(.*?)\\\\]','',x) #remove de-identified brackets\n",
    "    y=re.sub('[0-9]+\\.','',y) #remove 1.2. since the segmenter segments based on this\n",
    "    y=re.sub('dr\\.','doctor',y)\n",
    "    y=re.sub('m\\.d\\.','md',y)\n",
    "    y=re.sub('admission date:','',y)\n",
    "    y=re.sub('discharge date:','',y)\n",
    "    y=re.sub('--|__|==','',y)\n",
    "    # remove, digits, spaces\n",
    "    result = \" \".join(y.split())\n",
    "    \n",
    "    return result\n",
    "\n",
    "def make_str(lst):\n",
    "    string = \"\"\n",
    "    for sentence in lst:\n",
    "        string += (sentence+\"\\n\")\n",
    "        \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20fff62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set count:  36753\n",
      "Test set count:  9189\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['information'].values, df['readmission'].values, \n",
    "                                                    test_size=0.2, random_state=11)\n",
    "\n",
    "print('Train set count: ', len(X_train))\n",
    "print('Test set count: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a7b725f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17604\\3900244962.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bvanaken/CORe-clinical-mortality-prediction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp2\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2376\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_valid_text_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2377\u001b[0m             raise ValueError(\n\u001b[1;32m-> 2378\u001b[1;33m                 \u001b[1;34m\"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2379\u001b[0m                 \u001b[1;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2380\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertForSequenceClassification \n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bvanaken/CORe-clinical-mortality-prediction')\n",
    "model = BertForSequenceClassification.from_pretrained(\"bvanaken/CORe-clinical-mortality-prediction\")\n",
    "\n",
    "train_input = tokenizer(X_train, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "test_input = tokenizer(X_test, truncation=True, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c076cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mimicdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = mimicdataset(train_input, y_train)\n",
    "test_dataset = mimicdataset(test_input, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f470283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Trainer에서 사용할 하이퍼 파라미터 지정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # 모형 예측이나 체크포인트 출력 폴더, 반드시 필요함\n",
    "    num_train_epochs=2,              # 학습 에포크 수\n",
    "    per_device_train_batch_size=8,   # 학습에 사용할 배치 사이즈\n",
    "    per_device_eval_batch_size=16,   # 평가에 사용할 배치 사이즈\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                     # 학습할 모형\n",
    "    args=training_args,              # 위에서 정의한 학습 매개변수\n",
    "    train_dataset=train_dataset,     # 훈련 데이터셋\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 미세조정학습 실행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ad88fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267f807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc971800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb20acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f8f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2",
   "language": "python",
   "name": "nlp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
